{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rozpoznawanie(obraz, model):\n",
    "    obraz = cv2.cvtColor(obraz, cv2.COLOR_BGR2RGB)\n",
    "    obraz.flags.writeable = False\n",
    "    wynik = model.process(obraz)\n",
    "    obraz.flags.writeable = True                   \n",
    "    obraz = cv2.cvtColor(obraz, cv2.COLOR_RGB2BGR)\n",
    "    return obraz, wynik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def szkielet(obraz, wyniki):\n",
    "    mp_drawing.draw_landmarks(obraz, wyniki.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(obraz, wyniki.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "SCIEZKA = os.path.join('MP_Datatest')  \n",
    "\n",
    "gesty = np.array(['czesc','dziekuje'])\n",
    "\n",
    "liczba_sekwencji = 30\n",
    "\n",
    "dlugosc_sekwencji = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zwroc_punkty(wyniki):\n",
    "    lewa = np.zeros(21*3)\n",
    "    prawa = np.zeros(21*3)\n",
    "\n",
    "    if wyniki.left_hand_landmarks:\n",
    "        lewa = np.array([[res.x, res.y, res.z] for res in wyniki.left_hand_landmarks.landmark]).flatten()\n",
    "\n",
    "    if wyniki.right_hand_landmarks:\n",
    "        prawa = np.array([[res.x, res.y, res.z] for res in wyniki.right_hand_landmarks.landmark]).flatten()\n",
    "\n",
    "    return np.concatenate([ lewa, prawa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwy_mapa = {nazwa:num for num, nazwa in enumerate(gesty)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'czesc': 0, 'dziekuje': 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nazwy_mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sekwencje, nazwy = [], []\n",
    "for akcja in gesty:\n",
    "    for sekwencja in range(liczba_sekwencji):\n",
    "        okno = []\n",
    "        for nr_klatki in range(dlugosc_sekwencji):\n",
    "            res = np.load(os.path.join(SCIEZKA, akcja, str(sekwencja), \"{}.npy\".format(nr_klatki)))\n",
    "            okno.append(res)\n",
    "        sekwencje.append(okno)\n",
    "        nazwy.append(nazwy_mapa[akcja])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sekwencje)\n",
    "y = to_categorical(nazwy).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 30, 126)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,\n",
    "                                              stratify=y,random_state=1 )\n",
    "X_valid,X_test,y_valid,y_test=train_test_split(X_test,y_test,test_size=0.5,\n",
    "                                              stratify=y_test,random_state=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stworz_model(X_train, y_train, X_test, y_test):\n",
    "\tl_krokow, l_featerow, l_outputow = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(l_krokow,l_featerow)))\n",
    "\tmodel.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(tf.keras.layers.Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(l_outputow, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=stworz_model(X_train,y_train, X_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.9372 - accuracy: 0.4722 - val_loss: 0.5266 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5348 - accuracy: 0.5000 - val_loss: 0.4345 - val_accuracy: 0.5833\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4440 - accuracy: 0.5000 - val_loss: 0.3133 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2780 - accuracy: 0.9722 - val_loss: 0.2077 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1381 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.0930e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4405e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2281e-04 - accuracy: 1.0000 - val_loss: 8.9147e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8068e-05 - accuracy: 1.0000 - val_loss: 5.4941e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.0165e-05 - accuracy: 1.0000 - val_loss: 3.5122e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6897e-05 - accuracy: 1.0000 - val_loss: 2.3168e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.1955e-06 - accuracy: 1.0000 - val_loss: 1.5728e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.9637e-06 - accuracy: 1.0000 - val_loss: 1.0968e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1126e-06 - accuracy: 1.0000 - val_loss: 7.8552e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                  validation_data=(X_valid,y_valid),\n",
    "                  batch_size=128,\n",
    "                  epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2160e-04 - accuracy: 1.0000\n",
      "Test score: 0.00012159927428001538\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score,acc=model.evaluate(X_test,y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolory = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prawdopodobienstwo(res, gesty, klatka_wejsciowa, kolory):\n",
    "    klatka_wyjsciowa = klatka_wejsciowa.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(klatka_wyjsciowa, (0,60+num*40), ((prob*100).astype(int), 90+num*40), kolory[num], -1)\n",
    "        cv2.putText(klatka_wyjsciowa, gesty[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return klatka_wyjsciowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "czesc\n"
     ]
    }
   ],
   "source": [
    "sekwencja = []\n",
    "zdanie = []\n",
    "prog = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        wartosc, klatka = cap.read()\n",
    "\n",
    "        obraz, wyniki = rozpoznawanie(klatka, holistic)\n",
    "        \n",
    "        szkielet(obraz, wyniki)\n",
    "        \n",
    "        keypoints = zwroc_punkty(wyniki)\n",
    "        \n",
    "        sekwencja.append(keypoints)\n",
    "        sekwencja = sekwencja[-30:]\n",
    "        \n",
    "        if len(sekwencja) == 30:\n",
    "            res = model.predict(np.expand_dims(sekwencja, axis=0))[0]\n",
    "            print(gesty[np.argmax(res)])\n",
    "            \n",
    "            \n",
    "            if res[np.argmax(res)] > prog: \n",
    "                if len(zdanie) > 0: \n",
    "                    if gesty[np.argmax(res)] != zdanie[-1]:\n",
    "                        zdanie.append(gesty[np.argmax(res)])\n",
    "                else:\n",
    "                    zdanie.append(gesty[np.argmax(res)])\n",
    "\n",
    "            if len(zdanie) > 5: \n",
    "                zdanie = zdanie[-5:]\n",
    "\n",
    "            obraz = prawdopodobienstwo(res, gesty, cv2.flip(obraz, 1), kolory)\n",
    "            \n",
    "        cv2.rectangle(obraz, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(obraz, ' '.join(zdanie), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow('Jezyk migowy', obraz)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a782e78c516a0591e27701d1f830b917a27108ff0d49951d1f9790dfad5ff2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
